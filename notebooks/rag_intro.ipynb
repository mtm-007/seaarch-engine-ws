{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efb2f63-0345-4afc-a02b-5072ab78bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8bcaf9-f691-46e0-a903-76b3db0fd455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/parse-faq.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824cafc0-d0f3-4b7e-8875-dfc718413168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fdde46-d09e-4680-8d13-e4e2898e47c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents=[]\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f094e2-04f7-45d7-9424-292f4638c035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"dThe purpose of this document is to capture frequently asked technical questions\\nThe next cohort starts in Jan 2025. More info at DTC Article.\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start？',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b39fd62f-a5f1-44ca-a007-8f0f74c3e7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x151770ca0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Index = minsearch.Index(\n",
    "    text_fields = ['question','section','text'],\n",
    "    keyword_fields = ['course']\n",
    ")\n",
    "\n",
    "Index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b3fe1-4cb9-4b60-95e0-92d921eb457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = \"how to parse document files with python?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd3dac-03b2-4a87-9441-895f9c481740",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = {'question': 3, 'section' : 0.4}\n",
    "\n",
    "results = Index.search(\n",
    "    query=ques,\n",
    "    filter_dict={'course':'mlops-zoomcamp'},\n",
    "    boost_dict=boost,\n",
    "    num_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae810405-4cc3-4156-ba50-d32ef25aae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598bcd2-bb96-406c-af22-3bc1fed6ceba",
   "metadata": {},
   "source": [
    "#### from search script TextSearch Class function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e652a229-abfb-4281-a613-a8e9a7cdb99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Search_uncln import TextSearch\n",
    "\n",
    "index = TextSearch(\n",
    "    text_fields = ['question','section','text'],\n",
    ")\n",
    "index.fit(documents)\n",
    "\n",
    "se_results =index.search(\n",
    "    query = ques,\n",
    "    n_results= 2, \n",
    "    filters= {'course':'mlops-zoomcamp'},\n",
    "boost = {'question':6, 'section':0.2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475efc05-d3e4-4b54-a66f-fe8e41edb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03c8c9-8944-4b1c-ac98-0ec8ed77c137",
   "metadata": {},
   "source": [
    "### chatcompletition, Prompt Template, LLM api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d197dc6-d020-49e5-84e5-331aa09c9a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "973b6fdf-6210-4bd6-b23c-5c4a450d4135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x723c643e3d90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents=[]\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)\n",
    "        \n",
    "boost = {'question': 3, 'section' : 0.4}\n",
    "\n",
    "ques = \"how to parse document files with python?\" # query\n",
    "\n",
    "results = Index.search(\n",
    "    query=ques,\n",
    "    filter_dict={'course':'mlops-zoomcamp'},\n",
    "    boost_dict=boost,\n",
    "    num_results=5\n",
    ")\n",
    "\n",
    "Index = minsearch.Index(\n",
    "    text_fields = ['question','section','text'],\n",
    "    keyword_fields = ['course']\n",
    ")\n",
    "\n",
    "Index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "741b5697-b2f3-49ab-b568-6c8dec04351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\" \n",
    "You are an expert machine learning and mlops engineering helping a junior engineer as an assitant and guide. \n",
    "Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering.\n",
    "if the CONTEXT does not contain the answer, Output \"Not FOUND in the context given\" and explain your answer with reasons.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: {context}\n",
    "\"\"\".strip()\n",
    "\n",
    "context = \"\"\n",
    "\n",
    "for doc in results:\n",
    "    context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "prompt = prompt_template.format(question=ques, context=context).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce7dd538-223f-49ba-a7e1-d155e38b5ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert machine learning and mlops engineering helping a junior engineer as an assitant and guide. \n",
      "Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering.\n",
      "if the CONTEXT does not contain the answer, Output \"Not FOUND in the context given\" and explain your answer with reasons.\n",
      "\n",
      "QUESTION: how to parse document files with python?\n",
      "\n",
      "CONTEXT: section: Module 1: Introduction\n",
      "question: .gitignore how-to\n",
      "answer: If you create a folder data and download datasets or raw files in your local repository. Then to push all your code to remote repository without this files or folder please use gitignore file. The simple way to create it do the following steps\n",
      "1. Create empty .txt file (using text editor or command line)\n",
      "2. Safe as .gitignore (. must use the dot symbol)\n",
      "3. Add rules\n",
      " *.parquet - to ignore all parquet files\n",
      "data/ - to ignore all files in folder data\n",
      "\n",
      "For more pattern read GIT documentation\n",
      "https://git-scm.com/docs/gitignore\n",
      "Added by Olga Rudakova (olgakurgan@gmail.com)\n",
      "\n",
      "section: Module 1: Introduction\n",
      "question: Reading large parquet files\n",
      "answer: I have faced a problem while reading the large parquet file. I tried some workarounds but they were NOT successful with Jupyter.\n",
      "The error message is:\n",
      "IndexError: index 311297 is out of bounds for axis 0 with size 131743\n",
      "I solved it by performing the homework directly as a python script.\n",
      "Added by Ibraheem Taha (ibraheemtaha91@gmail.com)\n",
      "You can try using the Pyspark library\n",
      "Answered by kamaldeen (kamaldeen32@gmail.com)\n",
      "\n",
      "section: Module 1: Introduction\n",
      "question: How to replace distplot with histplot\n",
      "answer: sns.distplot(df_train[\"duration\"])\n",
      "Can be replaced with\n",
      "sns.histplot(\n",
      "df_train[\"duration\"] , kde=True,\n",
      "stat=\"density\", kde_kws=dict(cut=3), bins=50,\n",
      "alpha=.4, edgecolor=(1, 1, 1, 0.4),\n",
      ")\n",
      "To get almost identical result\n",
      "\n",
      "section: Module 4: Deployment\n",
      "question: Pipenv with Jupyter\n",
      "answer: Problem description. How can we use Jupyter notebooks with the Pipenv environment?\n",
      "Solution: Refer to this stackoverflow question. Basically install jupyter and ipykernel using pipenv. And then register the kernel with `python -m ipykernel install --user --name=my-virtualenv-name` inside the Pipenv shell. If you are using Jupyter notebooks in VS Code, doing this will also add the virtual environment in the list of kernels.\n",
      "Added by Ron Medina\n",
      "\n",
      "section: General course questions\n",
      "question: Course - How do I start?\n",
      "answer: No matter if you're with a 'live' cohort or follow on the self-paced mode, the way to start is similar:\n",
      "see what things are where by reading  pins and  bookmarks on the course-channel\n",
      "reading the repo (bookmarked in channel) and watching the video lessons (playlist bookmarked in channel)\n",
      "if have questions, search the channel itself first; someone may have already asked and gotten a solution\n",
      "if don't want to comb through the search results, read  for the most Frequently Asked Questions (this document)\n",
      "if don't even want to read/skim/search (use ctrl+F) the questions in FAQ doc, tag the @ZoomcampQABot when you ask questions, and it will summarize it for you (if answers in its knowledge-base)\n",
      "For generic, non-zoomcamp queries, you can also ask ChatGPT/BingCopilot/GoogleGemini/etc, especially for error messages\n",
      "check if you're on track by checking the deadlines (in Course Management form for Homework submissions)\n",
      "main difference of not being in a “live” cohort is that the responses to your questions might be delayed as not many active students come online anymore. Which is not an issue if you do your own due diligence and search for answers first or reading the documentation of the library.\n",
      "If you do need to ask questions when no answers supplied in resources above have helped, follow the asking-questions.md (bookmarked in channel) guidelines, also in Pins…\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d69ac5c5-cb09-47e0-b89f-297d092cc016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I understand your question as \"How to parse document files with Python?\"\\n\\n Based on the provided context, I did not find a direct answer to your question. However, I found a section related to \"Reading large parquet files\" which mentions using the Pyspark library. But it\\'s not directly relevant to parsing document files with Python.\\n\\nTherefore, I will output \"Not FOUND in the context given\" with the reason that the context does not contain a direct answer to parsing document files with Python. If you\\'re interested in parsing document files with Python, I can assist you in finding the most relevant and accurate information from other resources or provide some general guidance on how to start.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = Groq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce318635-02e5-4ff5-b8b1-bb43c64dfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3, 'section' : 0.4}\n",
    "\n",
    "    results = Index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course':'mlops-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    ")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2012a964-1060-46ae-80f4-df245cf0ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\" \n",
    "You are an expert machine learning and mlops engineering helping a junior engineer as an assitant and guide. \n",
    "Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering. DO NOT USE OTHER CONTENT OTHER THAN GIVEN CONTEXT!\n",
    "if the CONTEXT does not contain the answer, Output \"Not FOUND in the context given\" and explain your answer with reasons.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: {context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7756d4e-ddfd-455b-8b46-838c2c416e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(prompt):\n",
    "    client = Groq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    ")\n",
    "    response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "    return print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71d5e338-dfc8-4130-9a8f-d0fc01bb9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = \"How to use mlflow for experiment tracking?\"\n",
    "def rag(query):\n",
    "    \n",
    "    search_results = search(query)\n",
    "    Prompt = build_prompt(query, search_results)\n",
    "    answer = llm_call(Prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f036cc67-265c-40c3-83b5-37033b64b3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A question about using MLflow for experiment tracking!\n",
      "\n",
      "You're asking how to use MLflow for experiment tracking. Unfortunately, I don't see a direct answer to this question in the provided context. The context only provides questions and answers about specific issues with setting up and using MLflow, such as how to delete an experiment permanently, why an experiment is not visible in the MLflow UI, and how to set up MLflow for experiment tracking on GCP.\n",
      "\n",
      "However, I can provide some general information about using MLflow for experiment tracking. MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It allows you to track experiments, version datasets, and reproduce results.\n",
      "\n",
      "To use MLflow for experiment tracking, you'll need to set up a tracking URI, which is the location where MLflow will store your experiment data. You can set the tracking URI using the `mlflow.set_tracking_uri()` function.\n",
      "\n",
      "For example, you can use the following code to set up an SQLite tracking URI:\n",
      "```python\n",
      "import mlflow\n",
      "mlflow.set_tracking_uri('sqlite:///my_mlflow_tracker.db')\n",
      "```\n",
      "This sets up an SQLite database at `my_mlflow_tracker.db` as the tracking URI. You can then use the `mlflow.start_run()` function to start a new experiment, and the `mlflow.log_param()`, `mlflow.log_metric()`, and `mlflow.log_artifact()` functions to log parameters, metrics, and artifacts to the experiment.\n",
      "\n",
      "If you're using a different database, such as PostgreSQL or S3, you'll need to use a different tracking URI. For example, to use PostgreSQL, you might use:\n",
      "```python\n",
      "mlflow.set_tracking_uri('postgresql://user:password@host:port/dbname')\n",
      "```\n",
      "And to use S3, you might use:\n",
      "```python\n",
      "mlflow.set_tracking_uri('s3://my-bucket/mlflow')\n",
      "```\n",
      "I hope this helps! Let me know if you have any further questions.\n"
     ]
    }
   ],
   "source": [
    "rag(Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dff91e5c-b084-4db0-b3ff-789a259ecd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not FOUND in the context given.\n",
      "\n",
      "The provided context does not contain information on how to run Kafka. It seems to cover topics related to Gitignore, deployment, experiment tracking, and general course questions, but does not mention Kafka.\n"
     ]
    }
   ],
   "source": [
    "rag(\"How to run Kafka?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f95915a8-3610-4d08-aae6-0dd99e9b20a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"dThe purpose of this document is to capture frequently asked technical questions\\nThe next cohort starts in Jan 2025. More info at DTC Article.\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start？',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd2eaca-c385-4a73-ab1b-8cc71ec55c95",
   "metadata": {},
   "source": [
    "## With Elastic Search proper Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcda898a-3389-4a41-9cf2-96c109aa6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d26e34-739c-4911-b9c5-ce2a278b778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cab09eb-4d20-4b52-9b59-b5b60c3d9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#es_client.info()   #--to get the setup info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8de332-c7ca-4cce-ae48-656144113f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_Settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course_faq_questions\" #must be lowercase\n",
    "\n",
    "#create an index, only run one time as it is persistent\n",
    "es_client.indices.create(index= index_name, body=index_Settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73ee85bf-5191-4b8f-b0b6-a3f90bb00000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23db432e-fb72-426e-8b03-c397b52f07f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7ad8cf4af54bbe89e874cc0e759a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc227047-7e0d-41f3-afbe-3fc71292e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I Run Kafka?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f2c9197-0f25-4660-9c23-3b40253053ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index= index_name, body= search_query)     \n",
    "    \n",
    "    hits_results = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        hits_results.append(hit['_source'])\n",
    "    \n",
    "    return hits_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acd2e00a-0037-4130-8982-c8b23031ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_elastic(query):\n",
    "    \n",
    "    search_results = elastic_search(query)\n",
    "    Prompt = build_prompt(query, search_results)\n",
    "    answer = llm_call(Prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "431c3e56-72b0-4171-bac5-d48f0f58db7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the CONTEXT provided, I can answer the question:\n",
      "\n",
      "How do I Run Kafka?\n",
      "\n",
      "The answer is not directly provided in the given CONTEXT. However, we can find related information in the section \"Module 6: streaming with kafka\" under the question \"Java Kafka: How to run producer/consumer/kstreams/etc in terminal\".\n",
      "\n",
      "According to this answer, to run Kafka using Java, you can execute the command:\n",
      "\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "\n",
      "In this context, it seems that the command is specific to running a Java producer/consumer/kstreams application. If you're looking for general information on running Kafka, the CONTEXT does not provide a direct answer.\n",
      "\n",
      "Therefore, my output is:\n",
      "\n",
      "Not FOUND in the context given\n",
      "\n",
      "Reason: The CONTEXT does not provide a direct answer to running Kafka, but it does offer related information for running a specific Java application using Kafka.\n"
     ]
    }
   ],
   "source": [
    "rag_with_elastic(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a0c5e9-5d2a-4414-bc16-082d20c159a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
