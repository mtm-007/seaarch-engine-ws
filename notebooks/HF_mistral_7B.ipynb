{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b03c8c9-8944-4b1c-ac98-0ec8ed77c137",
   "metadata": {},
   "source": [
    "### chatcompletition, Prompt Template, LLM api call with Open Source LLMs,with local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d197dc6-d020-49e5-84e5-331aa09c9a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973b6fdf-6210-4bd6-b23c-5c4a450d4135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f24113b2fe0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents=[]\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)\n",
    "        \n",
    "Index = minsearch.Index(\n",
    "    text_fields = ['question','section','text'],\n",
    "    keyword_fields = ['course']\n",
    ")  \n",
    "\n",
    "Index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce318635-02e5-4ff5-b8b1-bb43c64dfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3, 'section' : 0.4}\n",
    "\n",
    "    results = Index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course':'mlops-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    ")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d5e338-dfc8-4130-9a8f-d0fc01bb9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    \n",
    "    search_results = search(query)\n",
    "    Prompt = build_prompt(query, search_results)\n",
    "    answer = llm_call(Prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481f53d-29f0-4cdd-9618-58e0547d65ce",
   "metadata": {},
   "source": [
    "### Mistral-7B openSource LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693a5d55-c872-4624-814d-0faae8cfe64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6040235-f8b4-4e3b-8e3b-329c00a40cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc729957-fc23-4fdd-9131-df30da036642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /teamspace/studios/this_studio/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(os.getenv(\"HF_zoomcamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "881bff8a-1d72-4e7c-af61-a8a4c7cad5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cec35d5e114b9ea9e0f7d6afabf06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.3\", device_map=\"auto\", load_in_4bit=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.3\", padding_side=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "933b45f7-5f93-417a-8f06-88be0edcd0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ff55640-1030-4a49-9990-89995ee972cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\" You are an expert in machine learning and MLOps, assisting a junior engineer. Your task is to answer the following question using only the provided context from the FAQ database. Do not include any information that is not present in the context. If the context does not provide an answer to the question, respond with \"Not FOUND in the context given\" and provide a brief explanation.\n",
    "\n",
    "QUESTION:{question}\n",
    "CONTEXT:{context}\n",
    "Answer:\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"{doc['question']}\\n{doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm_call(prompt):\n",
    "    response = generator(prompt, max_length=2048, do_sample=True, temperature=0.7,top_p = 0.95, num_return_sequences=1)\n",
    "    response_final = response[0]['generated_text']\n",
    "    return response_final[len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e14da2d-2d48-43fe-8a3c-aa9a676ac3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The reason you are getting this error is because you are trying to connect to an SSL server with Python 2.x. Python 2.x does not support SSL connections.\\n\\nYou should upgrade to Python 3.x to resolve the problem.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"How can I use Kafka?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bd7095e-8a51-44fd-b0ce-f32d101d25f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reason you are getting this error is because you are trying to connect to an SSL server with Python 2.x. Python 2.x does not support SSL connections.\n",
      "\n",
      "You should upgrade to Python 3.x to resolve the problem.\n"
     ]
    }
   ],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9c823-de9b-4493-8379-c879e2232d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644d53d-b790-48ae-9a89-e77873ad7589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b258b-9699-45cb-bbed-1bd408f12b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
