{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b03c8c9-8944-4b1c-ac98-0ec8ed77c137",
   "metadata": {},
   "source": [
    "### chatcompletition, Prompt Template, LLM api call with Open Source LLMs,with local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d197dc6-d020-49e5-84e5-331aa09c9a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973b6fdf-6210-4bd6-b23c-5c4a450d4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents=[]\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)\n",
    "        \n",
    "Index = minsearch.Index(\n",
    "    text_fields = ['question','section','text'],\n",
    "    keyword_fields = ['course']\n",
    ")  \n",
    "\n",
    "Index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce318635-02e5-4ff5-b8b1-bb43c64dfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3, 'section' : 0.4}\n",
    "\n",
    "    results = Index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course':'mlops-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    ")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2012a964-1060-46ae-80f4-df245cf0ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\" You are an expert in machine learning and MLOps, assisting a junior engineer. Your task is to answer the following question using only the provided context from the FAQ database. Do not include any information that is not present in the context. If the context does not provide an answer to the question, respond with \"Not FOUND in the context given\" and provide a brief explanation.\n",
    "\n",
    "**QUESTION:** How do I start using MLflow?\n",
    "\n",
    "**CONTEXT:** \n",
    "- Section: Module 2: Experiment Tracking\n",
    "  - Question: Viewing MLflow Experiments using MLflow CLI\n",
    "    - Answer: Problem: After starting the tracking server, when we try to use the mlflow CLI commands, most of them can’t find the experiments that have been run with the tracking server. Solution: Set the environment variable `MLFLOW_TRACKING_URI` to the URI of the SQLite database (e.g., `export MLFLOW_TRACKING_URI=sqlite:///{path to sqlite database}`). After this, view experiments from the command line using commands like `mlflow experiments search`.\n",
    "\n",
    "  - Question: When using Autologging, do I need to set a training parameter to track it on MLflow UI?\n",
    "    - Answer: No, autologging tracks the parameters automatically, even if you do not explicitly set them when calling `.fit`. You can set only the parameters you want during training, and all parameters will be visible in the MLflow UI.\n",
    "\n",
    "  - Question: WARNING: mlflow.sklearn: Failed to log training dataset information to MLflow Tracking.\n",
    "    - Answer: This warning occurs because MLflow expects the dataset to be in a `pd.DataFrame` format, but if you provide a `numpy.ndarray`, it fails. To avoid this, set `log_datasets = False` in the autolog function.\n",
    "\n",
    "  - Question: mlflow not showing artifacts\n",
    "    - Answer: When using local storage, start MLflow where `mlflow.db` is located. For example, if `mlflow.db` is in `mlops/mlflow`, navigate to that folder and run `../scripts/start.sh`.\n",
    "\n",
    "**ANSWER:**\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d5e338-dfc8-4130-9a8f-d0fc01bb9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = \"How to use mlflow for experiment tracking?\"\n",
    "def rag(query):\n",
    "    \n",
    "    search_results = search(query)\n",
    "    Prompt = build_prompt(query, search_results)\n",
    "    answer = llm_call(Prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481f53d-29f0-4cdd-9618-58e0547d65ce",
   "metadata": {},
   "source": [
    "### Mistral-7B openSource LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693a5d55-c872-4624-814d-0faae8cfe64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6040235-f8b4-4e3b-8e3b-329c00a40cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc729957-fc23-4fdd-9131-df30da036642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /teamspace/studios/this_studio/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(os.getenv(\"HF_zoomcamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "881bff8a-1d72-4e7c-af61-a8a4c7cad5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6bb42ee7ee423cb9958c89a08236fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2aae8c2e2446528094ad2c3654e701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6507d7d747f047d4896cec3cdaabf2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84c7ae00bc14102b060070839cf709e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5371d6f5b87d43968e36ebcb0c707f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440ad8f67c494d4db6aaa78c0dfc7f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e296f12f55fc48c38893bc24b650c85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddcd5ca7c58488cba5141dd49649767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.3\", device_map=\"auto\", load_in_4bit=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.3\", padding_side=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "933b45f7-5f93-417a-8f06-88be0edcd0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b42410db-22b6-46aa-afa6-a6f4bd4bd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" You are an expert in machine learning and MLOps, assisting a junior engineer. Your task is to answer the following question using only the provided context from the FAQ database. Do not include any information that is not present in the context. If the context does not provide an answer to the question, respond with \"Not FOUND in the context given\" and provide a brief explanation.\n",
    "\n",
    "**QUESTION:** How do I start using MLflow?\n",
    "\n",
    "**CONTEXT:** \n",
    "- Section: Module 2: Experiment Tracking\n",
    "  - Question: Viewing MLflow Experiments using MLflow CLI\n",
    "    - Answer: Problem: After starting the tracking server, when we try to use the mlflow CLI commands, most of them can’t find the experiments that have been run with the tracking server. Solution: Set the environment variable `MLFLOW_TRACKING_URI` to the URI of the SQLite database (e.g., `export MLFLOW_TRACKING_URI=sqlite:///{path to sqlite database}`). After this, view experiments from the command line using commands like `mlflow experiments search`.\n",
    "\n",
    "  - Question: When using Autologging, do I need to set a training parameter to track it on MLflow UI?\n",
    "    - Answer: No, autologging tracks the parameters automatically, even if you do not explicitly set them when calling `.fit`. You can set only the parameters you want during training, and all parameters will be visible in the MLflow UI.\n",
    "\n",
    "  - Question: WARNING: mlflow.sklearn: Failed to log training dataset information to MLflow Tracking.\n",
    "    - Answer: This warning occurs because MLflow expects the dataset to be in a `pd.DataFrame` format, but if you provide a `numpy.ndarray`, it fails. To avoid this, set `log_datasets = False` in the autolog function.\n",
    "\n",
    "  - Question: mlflow not showing artifacts\n",
    "    - Answer: When using local storage, start MLflow where `mlflow.db` is located. For example, if `mlflow.db` is in `mlops/mlflow`, navigate to that folder and run `../scripts/start.sh`.\n",
    "\n",
    "**ANSWER:**\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e50532-4495-40b5-af51-8c409dbc8ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = generator(prompt, max_length=1024, do_sample=True, temperature=0.7,top_p = 0.95, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db6193c8-7cf4-478f-8b93-c9c7d2fed916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in machine learning and MLOps, assisting a junior engineer. Your task is to answer the following question using only the provided context from the FAQ database. Do not include any information that is not present in the context. If the context does not provide an answer to the question, respond with \"Not FOUND in the context given\" and provide a brief explanation.\n",
      "\n",
      "**QUESTION:** How do I start using MLflow?\n",
      "\n",
      "**CONTEXT:** \n",
      "- Section: Module 2: Experiment Tracking\n",
      "  - Question: Viewing MLflow Experiments using MLflow CLI\n",
      "    - Answer: Problem: After starting the tracking server, when we try to use the mlflow CLI commands, most of them can’t find the experiments that have been run with the tracking server. Solution: Set the environment variable `MLFLOW_TRACKING_URI` to the URI of the SQLite database (e.g., `export MLFLOW_TRACKING_URI=sqlite:///{path to sqlite database}`). After this, view experiments from the command line using commands like `mlflow experiments search`.\n",
      "\n",
      "  - Question: When using Autologging, do I need to set a training parameter to track it on MLflow UI?\n",
      "    - Answer: No, autologging tracks the parameters automatically, even if you do not explicitly set them when calling `.fit`. You can set only the parameters you want during training, and all parameters will be visible in the MLflow UI.\n",
      "\n",
      "  - Question: WARNING: mlflow.sklearn: Failed to log training dataset information to MLflow Tracking.\n",
      "    - Answer: This warning occurs because MLflow expects the dataset to be in a `pd.DataFrame` format, but if you provide a `numpy.ndarray`, it fails. To avoid this, set `log_datasets = False` in the autolog function.\n",
      "\n",
      "  - Question: mlflow not showing artifacts\n",
      "    - Answer: When using local storage, start MLflow where `mlflow.db` is located. For example, if `mlflow.db` is in `mlops/mlflow`, navigate to that folder and run `../scripts/start.sh`.\n",
      "\n",
      "**ANSWER:**\n",
      "The first thing you need to do is to install MLflow. You can do this by running the following command in your terminal: `pip install mlflow`. Once MLflow is installed, you can start using it by running the following command: `mlflow --help`. This will show you the available commands and options for MLflow.\n",
      "\n",
      "Once you have MLflow installed and running, you can start tracking your experiments. To do this, you will need to set up a tracking server. You can do this by running the following command: `mlflow server --backend-store-uri sqlite:///mlruns.db`. This will start a tracking server that stores your experiments in a SQLite database.\n",
      "\n",
      "Once the tracking server is running, you can start tracking your experiments by running the following command: `mlflow.log_param(\"foo\", \"bar\")`. This will log the parameter \"foo\" with the value \"bar\" to the tracking server.\n",
      "\n",
      "You can also track the metrics of your experiments by running the following command: `mlflow.log_metric(\"foo\", 1.0)`. This will log the metric \"foo\" with the value 1.0 to the tracking server.\n",
      "\n",
      "Once you have tracked your experiments, you can view them by running the following command: `mlflow.list_experiments()`. This will list all of the experiments that have been tracked by MLflow.\n",
      "\n",
      "That's all there is to it! You can now start using MLflow to track your experiments and metrics.\n"
     ]
    }
   ],
   "source": [
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff55640-1030-4a49-9990-89995ee972cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6762f-0a9f-44dc-90d2-d9c6bda9eb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e138c9-c7a5-40b2-8f72-2f39f1290365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a4eb8a7-a1b6-472c-af34-52ca69000d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1259: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A list of colors: red, blue, green, yellow, orange, purple, pink,'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer([\"A list of colors: red, blue\"], return_tensors=\"pt\").to(\"cuda\")\n",
    "generated_ids = model.generate(**model_inputs)\n",
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f563d2c8-6f82-4c13-866f-63f30933e209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a466627a-575b-49d4-a4d3-c5d8043f75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(prompt):\n",
    "    model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "    generated_ids = model.generate(**model_inputs,max_length=1500)\n",
    "    result = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e14da2d-2d48-43fe-8a3c-aa9a676ac3b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'path to sqlite database'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrag\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow do i start using mlflow?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m, in \u001b[0;36mrag\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrag\u001b[39m(query):\n\u001b[1;32m      4\u001b[0m     search_results \u001b[38;5;241m=\u001b[39m search(query)\n\u001b[0;32m----> 5\u001b[0m     Prompt \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     answer \u001b[38;5;241m=\u001b[39m llm_call(Prompt)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "Cell \u001b[0;32mIn[21], line 28\u001b[0m, in \u001b[0;36mbuild_prompt\u001b[0;34m(query, search_results)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[1;32m     26\u001b[0m     context \u001b[38;5;241m=\u001b[39m context \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mquestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124manswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 28\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prompt\n",
      "\u001b[0;31mKeyError\u001b[0m: 'path to sqlite database'"
     ]
    }
   ],
   "source": [
    "rag(\"How do i start using mlflow?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7095e-8a51-44fd-b0ce-f32d101d25f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9c823-de9b-4493-8379-c879e2232d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644d53d-b790-48ae-9a89-e77873ad7589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b258b-9699-45cb-bbed-1bd408f12b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
